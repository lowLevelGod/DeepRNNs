Treebank wordlevel
-> DEPTH comparision

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Model Name} & \textbf{Depth} & \textbf{Train Loss} & \textbf{Train Acc (\%)} & \textbf{Val Loss} & \textbf{Val Acc (\%)} \\
\hline
DT(S)-RNN  & 2  & 3.0057 & 13.46 & 3.0988 & 6.47  \\
DT(S)-RNN  & 3  & 3.0346 & 12.55 & 3.1125 & 13.29 \\
DT(S)-RNN  & 5  & 3.0344 & 12.70 & 3.2379 & 8.36  \\
DT(S)-RNN  & 6  & 3.0341 & 12.66 & 3.1773 & 8.36  \\
DT(S)-RNN  & 7  & 3.0344 & 12.58 & 3.0867 & 10.30 \\
DT(S)-RNN  & 8  & 3.0347 & 12.50 & 3.1037 & 10.30 \\
DT(S)-RNN  & 9  & 3.0319 & 12.54 & 3.1660 & 10.30 \\
DT(S)-RNN  & 10 & 3.0346 & 12.57 & 3.1435 & 8.36  \\
\hline
DOT(S)-RNN & 2  & 8.5650 & 13.24 & 8.5536 & 13.29 \\
DOT(S)-RNN & 3  & 8.5655 & 13.24 & 8.5540 & 13.29 \\
DOT(S)-RNN & 5  & 8.5657 & 13.24 & 8.5541 & 13.29 \\
DOT(S)-RNN & 6  & 8.5650 & 13.24 & 8.5535 & 13.29 \\
DOT(S)-RNN & 7  & 8.5651 & 13.24 & 8.5536 & 13.29 \\
DOT(S)-RNN & 8  & 8.5650 & 13.24 & 8.5536 & 13.29 \\
\hline
\end{tabular}
\caption{Final epoch results for different depths of DT(S)-RNN and DOT(S)-RNN models}
\label{tab:merged_rnn_depth_results}
\end{table}


-> Hidden size:

\begin{table}[ht]
\centering
\caption{Training Results for Various RNN Architectures on Treebank Word-Level}
\label{tab:rnn_all_results}
\begin{tabular}{cccccc}
\toprule
\textbf{Model} & \textbf{Hidden Size} & \textbf{Train Loss} & \textbf{Train Acc (\%)} & \textbf{Val Loss} & \textbf{Val Acc (\%)} \\
\midrule
RNN           & 100  & 2.39 & 30.82 & 2.42 & 28.20 \\
RNN           & 200  & 2.27 & 33.64 & 2.71 & 23.22 \\
RNN           & 300  & 2.22 & 34.78 & 3.27 & 16.26 \\
RNN           & 400  & 2.19 & 35.43 & 2.43 & 31.44 \\
RNN           & 500  & 2.15 & 36.23 & 2.61 & 27.08 \\
RNN           & 600  & 2.13 & 37.04 & 2.53 & 29.91 \\
RNN           & 700  & 2.11 & 37.36 & 2.65 & 28.11 \\
\midrule
DT(S)-RNN     & 100  & 3.03 & 12.78 & 3.10 & 5.43  \\
DT(S)-RNN     & 200  & 3.04 & 12.43 & 3.11 & 13.29 \\
DT(S)-RNN     & 300  & 3.04 & 12.35 & 3.25 & 10.30 \\
DT(S)-RNN     & 400  & 3.04 & 12.23 & 3.19 & 10.30 \\
DT(S)-RNN     & 500  & 3.04 & 12.33 & 3.20 & 9.14  \\
DT(S)-RNN     & 600  & 3.04 & 12.51 & 3.14 & 12.07 \\
DT(S)-RNN     & 700  & 3.05 & 12.40 & 3.12 & 13.29 \\
\midrule
DOTS RNN      & 100  & 2.67 & 23.15 & 2.78 & 20.54 \\
DOTS RNN      & 200  & 2.52 & 27.10 & 2.66 & 24.46 \\
DOTS RNN      & 300  & 2.44 & 29.32 & 2.59 & 25.58 \\
DOTS RNN      & 400  & 2.40 & 30.17 & 2.57 & 24.32 \\
DOTS RNN      & 500  & 2.37 & 31.12 & 2.53 & 26.53 \\
DOTS RNN      & 600  & 2.34 & 31.75 & 2.51 & 26.95 \\
DOTS RNN      & 700  & 2.33 & 32.15 & 2.50 & 27.15 \\
\midrule
Stacked RNN   & 100  & 2.55 & 26.54 & 2.66 & 22.30 \\
Stacked RNN   & 200  & 2.40 & 29.87 & 2.58 & 25.09 \\
Stacked RNN   & 300  & 2.33 & 31.02 & 2.54 & 26.01 \\
Stacked RNN   & 400  & 2.30 & 31.50 & 2.53 & 26.37 \\
Stacked RNN   & 500  & 2.28 & 31.97 & 2.51 & 26.64 \\
Stacked RNN   & 600  & 2.27 & 32.14 & 2.50 & 26.78 \\
Stacked RNN   & 700  & 2.26 & 32.29 & 2.49 & 26.95 \\
\bottomrule
\end{tabular}
\end{table}



-> transition size
\begin{table}[ht]
\centering
\caption{Training and Validation Results for DT(S)-RNN and DOT(S)-RNN Models with Various Transition Sizes}
\label{tab:joint_results}
\begin{tabular}{c|c|cc|cc}
\hline
Transition Size & Model Name & Train Loss & Train Acc (\%) & Val Loss & Val Acc (\%) \\
\hline
100 & DT(S)-RNN & 3.0363 & 12.63 & 3.0969 & 13.29 \\
100 & DOT(S)-RNN & 8.7779 & 13.24 & 8.7371 & 13.29 \\
200 & DT(S)-RNN & 3.0377 & 12.33 & 3.2143 & 13.29 \\
200 & DOT(S)-RNN & 8.7808 & 13.24 & 8.7397 & 13.29 \\
300 & DT(S)-RNN & 3.0400 & 12.26 & 3.3207 & 3.45 \\
300 & DOT(S)-RNN & 8.7798 & 13.24 & 8.7390 & 13.29 \\
400 & DT(S)-RNN & 3.0410 & 12.28 & 3.1609 & 7.46 \\
400 & DOT(S)-RNN & 8.7783 & 13.24 & 8.7374 & 13.29 \\
500 & DT(S)-RNN & 3.0419 & 12.13 & 3.1326 & 10.30 \\
500 & DOT(S)-RNN & 8.7820 & 13.24 & 8.7409 & 13.29 \\
600 & DT(S)-RNN & 3.0418 & 12.26 & 3.3653 & 3.45 \\
600 & DOT(S)-RNN & 8.7822 & 13.24 & 8.7411 & 13.29 \\
\hline
\end{tabular}
\end{table}



TREEBANK char










